{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads a pre-trained HyperLightspeedBench (HLB) neural network for image classification on CIFAR-10 dataset and experiments with low-precision low-rank approximation of the weight matrices of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from functools import partial\n",
    "from typing import Callable, Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlb import repo_basepath\n",
    "from hlb.config import hyp\n",
    "from hlb.nn.speedyresnet import (\n",
    "    BatchNorm,\n",
    "    Conv,\n",
    "    ConvGroup,\n",
    "    FastGlobalMaxPooling,\n",
    "    Linear,\n",
    "    SpeedyResNet,\n",
    "    TemperatureScaler,\n",
    ")\n",
    "from hlb.utils import get_batches\n",
    "from lplr.compressors import lplr, direct_svd_quant\n",
    "from lplr.quantizers import quantize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_models(model: nn.Module, benchmark_model):\n",
    "    model.eval()\n",
    "    benchmark_model.eval()\n",
    "    model = model.to(device).float()\n",
    "    benchmark_model = benchmark_model.to(device).float()\n",
    "    data = torch.load(hyp[\"misc\"][\"data_location\"], map_location=device)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2, reduction=\"none\")\n",
    "\n",
    "    eval_batchsize = 2500\n",
    "    from collections import defaultdict\n",
    "\n",
    "    loss_list_val, acc_list = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    model_types = (\"Test model\", \"Benchmark Model\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in get_batches(data, key=\"eval\", batchsize=eval_batchsize):\n",
    "            input_tensors = inputs.float()\n",
    "\n",
    "            for mm, mt in zip((model, benchmark_model), model_types):\n",
    "                outputs = mm(input_tensors)\n",
    "                loss_val = loss_fn(outputs, targets).float().mean()\n",
    "                acc_val = (outputs.argmax(-1) == targets.argmax(-1)).float().mean()\n",
    "                logger.trace(f\"loss {loss_val:.3f} acc {acc_val:.3f} for {mt}\")\n",
    "\n",
    "                loss_list_val[mt].append(loss_val)\n",
    "                acc_list[mt].append(acc_val)\n",
    "\n",
    "    for mt in model_types:\n",
    "        avg_val_acc = torch.mean(torch.tensor(acc_list[mt])).item()\n",
    "        avg_val_loss = torch.mean(torch.tensor(loss_list_val[mt])).item()\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Avg Validation Accuracy: {avg_val_acc:.2f} and Avg Validation Loss {avg_val_loss} for {mt}\"\n",
    "        )\n",
    "    return (\n",
    "        torch.mean(torch.tensor(acc_list[\"Test model\"])).item(),\n",
    "        torch.mean(torch.tensor(loss_list_val[\"Test model\"])).item(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantize_layers(\n",
    "    model: nn.Module, compressor: Callable[[np.ndarray], np.ndarray] = lplr\n",
    ") -> nn.Module:\n",
    "    from copy import deepcopy\n",
    "\n",
    "    output_model = deepcopy(model)\n",
    "    # b1 = 8\n",
    "    # b2 = 8\n",
    "    # frac = 0.9\n",
    "    for name, param in output_model.named_parameters():\n",
    "        model_param = param.to(device).detach()\n",
    "        param_shape = model_param.shape\n",
    "        logger.trace(f\"Applying LPLR on {name} with shape {param_shape}\")\n",
    "        if param.ndim >= 2:\n",
    "            reshaped_param = model_param.reshape(param_shape[0], param_shape[1], -1)\n",
    "            out_param = torch.zeros_like(reshaped_param)\n",
    "            for idxs in range(reshaped_param.shape[-1]):\n",
    "                out_param[:, :, idxs] = compressor(reshaped_param[:, :, idxs])\n",
    "            param.data = out_param.reshape(param_shape)\n",
    "        elif param.ndim == 1:\n",
    "            param.data = quantize(model_param)\n",
    "    return output_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_location = repo_basepath / \"artifacts/hlb/checkpoints/trained-speedyresnet.pt\"\n",
    "model = torch.load(model_location, map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bit budgets\n",
    "B1 = 8\n",
    "B2 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp(param, fraction, b1, b2):\n",
    "    from math import ceil\n",
    "\n",
    "    rank = min(param.shape)\n",
    "    try:\n",
    "        out_rank = ceil(fraction * rank)\n",
    "        assert isinstance(out_rank, int)\n",
    "    except AssertionError as ae:\n",
    "        logger.error(f\"Wrong Out rank: {out_rank}\")\n",
    "        raise ae\n",
    "    logger.debug(f\"Shape: {param.shape} Input Rank: {rank} Output Rank: {out_rank}\")\n",
    "    return lplr(param, out_rank, b1, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_direct_svd(param, fraction, b1, b2):\n",
    "    from math import ceil\n",
    "\n",
    "    rank = min(param.shape)\n",
    "    try:\n",
    "        out_rank = ceil(fraction * rank)\n",
    "        assert isinstance(out_rank, int)\n",
    "    except AssertionError as ae:\n",
    "        logger.error(f\"Wrong Out rank: {out_rank}\")\n",
    "        raise ae\n",
    "    logger.debug(f\"Shape: {param.shape} Input Rank: {rank} Output Rank: {out_rank}\")\n",
    "    return direct_svd_quant(param, out_rank, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quantize models using LPLR\n",
    "\n",
    "quantized_models = {\n",
    "    f: quantize_layers(model, compressor=partial(comp, fraction=float(f), b1=B1, b2=B2))\n",
    "    for f in (\"0.7\", \"0.75\", \"0.8\", \"0.9\", \"0.95\", \"1.0\", \"1.1\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize models using direct SVD quant\n",
    "\n",
    "quantized_models_direct_svd = {\n",
    "    f: quantize_layers(model, compressor=partial(comp_direct_svd, fraction=float(f), b1=B1, b2=B2))\n",
    "    for f in (\"0.7\", \"0.75\", \"0.8\", \"0.9\", \"0.95\", \"1.0\", \"1.1\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LPLR quantized models\n",
    "\n",
    "acc = {}\n",
    "loss = {}\n",
    "\n",
    "for f, qm in quantized_models.items():\n",
    "    (acc[f], loss[f]) = evaluate_models(qm, model)\n",
    "    logger.info(f\"Computing fraction {f} with accuracy {acc[f]:.3f} and loss {loss[f]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate direct-SVD quantized models\n",
    "\n",
    "acc_direct_svd = {}\n",
    "loss_direct_svd = {}\n",
    "\n",
    "for f, qm in quantized_models_direct_svd.items():\n",
    "    (acc_direct_svd[f], loss_direct_svd[f]) = evaluate_models(qm, model)\n",
    "    logger.info(f\"Direct-SVD: Computing fraction {f} with accuracy {acc[f]:.3f} and loss {loss[f]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "frac = [float(x) for x in acc.keys()]\n",
    "plt.plot(frac, acc.values(), marker=\"o\", color=\"blue\", markersize=10, label=\"LPLR\")\n",
    "plt.plot(frac, acc_direct_svd.values(), marker=\"x\", color=\"red\", markersize=10, label=\"Direct SVD Quant\")\n",
    "plt.xlabel(\"Fraction of singular values retained\")\n",
    "plt.xticks(frac)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.title(f\"HLB accuracy on CIFAR-10 with B1 = {B1} and B2 = {B2}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
